{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cleaned-data-vc.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vaxView', 'year', 'value', 'lowerLimit', 'upperLimit', 'sampleSize',\n",
      "       'confidenceInterval', 'demographicClass', 'upperError', 'lowerError'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vaxView</th>\n",
       "      <th>year</th>\n",
       "      <th>value</th>\n",
       "      <th>lowerLimit</th>\n",
       "      <th>upperLimit</th>\n",
       "      <th>sampleSize</th>\n",
       "      <th>confidenceInterval</th>\n",
       "      <th>demographicClass</th>\n",
       "      <th>upperError</th>\n",
       "      <th>lowerError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016</td>\n",
       "      <td>75.8</td>\n",
       "      <td>0.674919</td>\n",
       "      <td>0.810251</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>0.232394</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.245211</td>\n",
       "      <td>0.226415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2001</td>\n",
       "      <td>93.4</td>\n",
       "      <td>0.904198</td>\n",
       "      <td>0.958561</td>\n",
       "      <td>0.011280</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.110063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1045</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2017</td>\n",
       "      <td>44.9</td>\n",
       "      <td>0.240043</td>\n",
       "      <td>0.607415</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.716475</td>\n",
       "      <td>0.525157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2006</td>\n",
       "      <td>88.2</td>\n",
       "      <td>0.817008</td>\n",
       "      <td>0.924755</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.179577</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.201258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1403</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2016</td>\n",
       "      <td>34.3</td>\n",
       "      <td>0.247578</td>\n",
       "      <td>0.359869</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.204225</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.169811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2005</td>\n",
       "      <td>88.8</td>\n",
       "      <td>0.809473</td>\n",
       "      <td>0.935660</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.207746</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.187739</td>\n",
       "      <td>0.242138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2009</td>\n",
       "      <td>45.4</td>\n",
       "      <td>0.240043</td>\n",
       "      <td>0.617230</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.665493</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.731801</td>\n",
       "      <td>0.540881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2008</td>\n",
       "      <td>93.9</td>\n",
       "      <td>0.891281</td>\n",
       "      <td>0.968375</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>0.126761</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.107280</td>\n",
       "      <td>0.163522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2013</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0.571582</td>\n",
       "      <td>0.788441</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.373239</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.371648</td>\n",
       "      <td>0.361635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016</td>\n",
       "      <td>96.3</td>\n",
       "      <td>0.936491</td>\n",
       "      <td>0.982552</td>\n",
       "      <td>0.007170</td>\n",
       "      <td>0.073944</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.065134</td>\n",
       "      <td>0.106918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1265 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vaxView  year  value  lowerLimit  upperLimit  sampleSize  \\\n",
       "676   0.000000  2016   75.8    0.674919    0.810251    0.012329   \n",
       "1097  0.000000  2001   93.4    0.904198    0.958561    0.011280   \n",
       "1045  0.666667  2017   44.9    0.240043    0.607415    0.000393   \n",
       "1396  0.000000  2006   88.2    0.817008    0.924755    0.004722   \n",
       "1403  0.666667  2016   34.3    0.247578    0.359869    0.011455   \n",
       "...        ...   ...    ...         ...         ...         ...   \n",
       "56    0.000000  2005   88.8    0.809473    0.935660    0.005815   \n",
       "385   0.666667  2009   45.4    0.240043    0.617230    0.000481   \n",
       "86    0.000000  2008   93.9    0.891281    0.968375    0.009138   \n",
       "876   0.000000  2013   70.5    0.571582    0.788441    0.002842   \n",
       "1712  0.000000  2016   96.3    0.936491    0.982552    0.007170   \n",
       "\n",
       "      confidenceInterval  demographicClass  upperError  lowerError  \n",
       "676             0.232394          0.416667    0.245211    0.226415  \n",
       "1097            0.091549          0.000000    0.091954    0.110063  \n",
       "1045            0.647887          0.833333    0.716475    0.525157  \n",
       "1396            0.179577          0.416667    0.172414    0.201258  \n",
       "1403            0.204225          0.333333    0.252874    0.169811  \n",
       "...                  ...               ...         ...         ...  \n",
       "56              0.207746          0.166667    0.187739    0.242138  \n",
       "385             0.665493          0.333333    0.731801    0.540881  \n",
       "86              0.126761          0.333333    0.107280    0.163522  \n",
       "876             0.373239          0.083333    0.371648    0.361635  \n",
       "1712            0.073944          0.166667    0.065134    0.106918  \n",
       "\n",
       "[1265 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(df, train_size = 0.7, test_size = 0.3, random_state = 100)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Applying scaler() to all the columns except the 'yes-no' and 'dummy' variables\n",
    "num_vars = ['vaxView', 'lowerLimit', 'upperLimit', 'sampleSize', 'confidenceInterval','demographicClass','upperError','lowerError']\n",
    "df_train[num_vars] = scaler.fit_transform(df_train[num_vars])\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vaxView</th>\n",
       "      <th>year</th>\n",
       "      <th>lowerLimit</th>\n",
       "      <th>upperLimit</th>\n",
       "      <th>sampleSize</th>\n",
       "      <th>confidenceInterval</th>\n",
       "      <th>demographicClass</th>\n",
       "      <th>upperError</th>\n",
       "      <th>lowerError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.674919</td>\n",
       "      <td>0.810251</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>0.232394</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.245211</td>\n",
       "      <td>0.226415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.904198</td>\n",
       "      <td>0.958561</td>\n",
       "      <td>0.011280</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.110063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1045</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.240043</td>\n",
       "      <td>0.607415</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.716475</td>\n",
       "      <td>0.525157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.817008</td>\n",
       "      <td>0.924755</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.179577</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.201258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1403</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.247578</td>\n",
       "      <td>0.359869</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.204225</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.169811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.809473</td>\n",
       "      <td>0.935660</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.207746</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.187739</td>\n",
       "      <td>0.242138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.240043</td>\n",
       "      <td>0.617230</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.665493</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.731801</td>\n",
       "      <td>0.540881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.891281</td>\n",
       "      <td>0.968375</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>0.126761</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.107280</td>\n",
       "      <td>0.163522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.571582</td>\n",
       "      <td>0.788441</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.373239</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.371648</td>\n",
       "      <td>0.361635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.936491</td>\n",
       "      <td>0.982552</td>\n",
       "      <td>0.007170</td>\n",
       "      <td>0.073944</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.065134</td>\n",
       "      <td>0.106918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1265 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vaxView  year  lowerLimit  upperLimit  sampleSize  confidenceInterval  \\\n",
       "676   0.000000  2016    0.674919    0.810251    0.012329            0.232394   \n",
       "1097  0.000000  2001    0.904198    0.958561    0.011280            0.091549   \n",
       "1045  0.666667  2017    0.240043    0.607415    0.000393            0.647887   \n",
       "1396  0.000000  2006    0.817008    0.924755    0.004722            0.179577   \n",
       "1403  0.666667  2016    0.247578    0.359869    0.011455            0.204225   \n",
       "...        ...   ...         ...         ...         ...                 ...   \n",
       "56    0.000000  2005    0.809473    0.935660    0.005815            0.207746   \n",
       "385   0.666667  2009    0.240043    0.617230    0.000481            0.665493   \n",
       "86    0.000000  2008    0.891281    0.968375    0.009138            0.126761   \n",
       "876   0.000000  2013    0.571582    0.788441    0.002842            0.373239   \n",
       "1712  0.000000  2016    0.936491    0.982552    0.007170            0.073944   \n",
       "\n",
       "      demographicClass  upperError  lowerError  \n",
       "676           0.416667    0.245211    0.226415  \n",
       "1097          0.000000    0.091954    0.110063  \n",
       "1045          0.833333    0.716475    0.525157  \n",
       "1396          0.416667    0.172414    0.201258  \n",
       "1403          0.333333    0.252874    0.169811  \n",
       "...                ...         ...         ...  \n",
       "56            0.166667    0.187739    0.242138  \n",
       "385           0.333333    0.731801    0.540881  \n",
       "86            0.333333    0.107280    0.163522  \n",
       "876           0.083333    0.371648    0.361635  \n",
       "1712          0.166667    0.065134    0.106918  \n",
       "\n",
       "[1265 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating the training set into target and predictor variables\n",
    "\n",
    "y_train = df_train.pop('value')\n",
    "x_train = df_train\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>value</td>      <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>4.462e+23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 05 May 2021</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:49:38</td>     <th>  Log-Likelihood:    </th>  <td>  25605.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1265</td>      <th>  AIC:               </th> <td>-5.119e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1256</td>      <th>  BIC:               </th> <td>-5.115e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>    6.9280</td> <td> 3.96e-09</td> <td> 1.75e+09</td> <td> 0.000</td> <td>    6.928</td> <td>    6.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vaxView</th>            <td> 3.197e-14</td> <td> 4.94e-11</td> <td>    0.001</td> <td> 0.999</td> <td>-9.68e-11</td> <td> 9.69e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>               <td>-1.955e-13</td> <td> 1.98e-12</td> <td>   -0.099</td> <td> 0.921</td> <td>-4.07e-12</td> <td> 3.68e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lowerLimit</th>         <td>   45.1510</td> <td> 1.76e-10</td> <td> 2.56e+11</td> <td> 0.000</td> <td>   45.151</td> <td>   45.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>upperLimit</th>         <td>   47.1322</td> <td>  2.1e-10</td> <td> 2.25e+11</td> <td> 0.000</td> <td>   47.132</td> <td>   47.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sampleSize</th>         <td> 1.776e-14</td> <td> 1.78e-10</td> <td> 9.96e-05</td> <td> 1.000</td> <td> -3.5e-10</td> <td>  3.5e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>confidenceInterval</th> <td>-2.061e-13</td> <td> 1.22e-09</td> <td>   -0.000</td> <td> 1.000</td> <td>-2.39e-09</td> <td> 2.39e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>demographicClass</th>   <td> 2.465e-14</td> <td> 4.93e-11</td> <td>    0.001</td> <td> 1.000</td> <td>-9.66e-11</td> <td> 9.67e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>upperError</th>         <td>  -13.4149</td> <td> 7.83e-10</td> <td>-1.71e+10</td> <td> 0.000</td> <td>  -13.415</td> <td>  -13.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lowerError</th>         <td>   15.4554</td> <td> 4.63e-10</td> <td> 3.34e+10</td> <td> 0.000</td> <td>   15.455</td> <td>   15.455</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>363.125</td> <th>  Durbin-Watson:     </th> <td>   0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  75.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.290</td>  <th>  Prob(JB):          </th> <td>4.85e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.957</td>  <th>  Cond. No.          </th> <td>2.09e+19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.17e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  value   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 4.462e+23\n",
       "Date:                Wed, 05 May 2021   Prob (F-statistic):               0.00\n",
       "Time:                        11:49:38   Log-Likelihood:                 25605.\n",
       "No. Observations:                1265   AIC:                        -5.119e+04\n",
       "Df Residuals:                    1256   BIC:                        -5.115e+04\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                  6.9280   3.96e-09   1.75e+09      0.000       6.928       6.928\n",
       "vaxView             3.197e-14   4.94e-11      0.001      0.999   -9.68e-11    9.69e-11\n",
       "year               -1.955e-13   1.98e-12     -0.099      0.921   -4.07e-12    3.68e-12\n",
       "lowerLimit            45.1510   1.76e-10   2.56e+11      0.000      45.151      45.151\n",
       "upperLimit            47.1322    2.1e-10   2.25e+11      0.000      47.132      47.132\n",
       "sampleSize          1.776e-14   1.78e-10   9.96e-05      1.000    -3.5e-10     3.5e-10\n",
       "confidenceInterval -2.061e-13   1.22e-09     -0.000      1.000   -2.39e-09    2.39e-09\n",
       "demographicClass    2.465e-14   4.93e-11      0.001      1.000   -9.66e-11    9.67e-11\n",
       "upperError           -13.4149   7.83e-10  -1.71e+10      0.000     -13.415     -13.415\n",
       "lowerError            15.4554   4.63e-10   3.34e+10      0.000      15.455      15.455\n",
       "==============================================================================\n",
       "Omnibus:                      363.125   Durbin-Watson:                   0.000\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               75.132\n",
       "Skew:                          -0.290   Prob(JB):                     4.85e-17\n",
       "Kurtosis:                       1.957   Cond. No.                     2.09e+19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.17e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a model with all the variables\n",
    "\n",
    "x_train_lin_model = sm.add_constant(x_train)\n",
    "\n",
    "limmodel_full = sm.OLS(y_train, x_train_lin_model).fit()\n",
    "\n",
    "limmodel_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model fitting indicates a strong multicollinearity. We shall use VIF to find the issues.\n",
    " # Creating a dataframe that will contain the names of all the feature variables and their VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x_train.values, i) for i in range(x_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train.drop('lowerLimit', 1,)\n",
    "\n",
    "# Build a fitted model after dropping the variable\n",
    "x_train_lm1 = sm.add_constant(x)\n",
    "\n",
    "lr_1 = sm.OLS(y_train, x_train_lm1).fit()\n",
    "\n",
    "# Printing the summary of the model\n",
    "print(lr_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.drop('confidenceInterval', 1,)\n",
    "\n",
    "# Build a fitted model after dropping the variable\n",
    "x_train_lm2 = sm.add_constant(x)\n",
    "\n",
    "lr_2 = sm.OLS(y_train, x_train_lm2).fit()\n",
    "\n",
    "# Printing the summary of the model\n",
    "print(lr_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.drop('year', 1,)\n",
    "\n",
    "# Build a fitted model after dropping the variable\n",
    "x_train_lm3 = sm.add_constant(x)\n",
    "\n",
    "lr_3 = sm.OLS(y_train, x_train_lm3).fit()\n",
    "\n",
    "# Printing the summary of the model\n",
    "print(lr_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.drop('lowerError', 1,)\n",
    "\n",
    "# Build a fitted model after dropping the variable\n",
    "x_train_lm4 = sm.add_constant(x)\n",
    "\n",
    "lr_4 = sm.OLS(y_train, x_train_lm4).fit()\n",
    "\n",
    "# Printing the summary of the model\n",
    "print(lr_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_price = lr_4.predict(x_train_lm4)\n",
    "\n",
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_price), bins = 20)\n",
    "fig.suptitle('Error Term Distribution', fontsize = 15)                  \n",
    "plt.xlabel('Errors', fontsize = 15)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test.pop('value')\n",
    "x_test = df_test\n",
    "\n",
    "# Adding constant variable to test dataframe\n",
    "x_test_m4 = sm.add_constant(x_test)\n",
    "\n",
    "# Creating X_test_m4 dataframe by dropping variables from X_test_m4\n",
    "x_test_m4 = x_test_m4.drop([\"lowerLimit\", \"confidenceInterval\", \"year\", \"lowerError\"], axis = 1)\n",
    "\n",
    "# Making predictions using the final model\n",
    "y_pred_m4 = lr_4.predict(x_test_m4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_true = y_test, y_pred = y_pred_m4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
